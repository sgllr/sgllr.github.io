[{"title":"ML_final_project","url":"/2020/12/21/ML-final-project/","content":"<h1 id=\"前期准备阶段\"><a href=\"#前期准备阶段\" class=\"headerlink\" title=\"前期准备阶段\"></a>前期准备阶段</h1><h4 id=\"多通道卷积与池化\"><a href=\"#多通道卷积与池化\" class=\"headerlink\" title=\"多通道卷积与池化\"></a>多通道卷积与池化</h4><p>在处理多通道输入数据时，<strong>池化层对每个输入通道分别池化，而不是像卷积层那样将各通道的输入按通道相加</strong>。</p>\n<h4 id=\"VGGNet的结构\"><a href=\"#VGGNet的结构\" class=\"headerlink\" title=\"VGGNet的结构\"></a>VGGNet的结构</h4><p><img src=\"https://res.cloudinary.com/sgllr/image/upload/v1608514052/vgg_cs7xlz.jpg\" alt=\"vgg\" style=\"zoom:50%;\" /></p>\n<ul>\n<li>VGGNet成功地构筑了16~19层深度的卷积神经网络</li>\n<li>VGGNet网络结构很规整，全部使用$3\\times 3$的小型卷积核以及$2\\times 2$的最大池化层（C有使用$1\\times 1$卷积核）<ul>\n<li>$3\\times 3$卷积核：stride = 1, padding = 1 (padding  = same convolution)</li>\n<li>$2\\times 2$最大池化层：stride = 2</li>\n</ul>\n</li>\n<li>每次池化后，图像高和宽均缩小一半（$2\\times 2\\ pooling$），初始为$224\\times 224$，经过5个卷积块（每层最后都是最大池化层）后图像（特征）大小变为$7\\times 7$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">cfgs = &#123;</span><br><span class=\"line\">    <span class=\"string\">&#x27;A&#x27;</span>: [<span class=\"number\">64</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">128</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"string\">&#x27;M&#x27;</span>],</span><br><span class=\"line\">    <span class=\"string\">&#x27;B&#x27;</span>: [<span class=\"number\">64</span>, <span class=\"number\">64</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"string\">&#x27;M&#x27;</span>],</span><br><span class=\"line\">    <span class=\"string\">&#x27;D&#x27;</span>: [<span class=\"number\">64</span>, <span class=\"number\">64</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"string\">&#x27;M&#x27;</span>],</span><br><span class=\"line\">    <span class=\"string\">&#x27;E&#x27;</span>: [<span class=\"number\">64</span>, <span class=\"number\">64</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"string\">&#x27;M&#x27;</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"string\">&#x27;M&#x27;</span>],</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make_layers</span>(<span class=\"params\">cfg, batch_norm=<span class=\"literal\">False</span></span>):</span></span><br><span class=\"line\">    layers = []</span><br><span class=\"line\">    in_channels = <span class=\"number\">3</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> v <span class=\"keyword\">in</span> cfg:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> v == <span class=\"string\">&#x27;M&#x27;</span>:</span><br><span class=\"line\">            layers += [nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>)]</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> batch_norm:</span><br><span class=\"line\">                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=<span class=\"literal\">True</span>)]</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                layers += [conv2d, nn.ReLU(inplace=<span class=\"literal\">True</span>)]</span><br><span class=\"line\">            in_channels = v</span><br><span class=\"line\">    <span class=\"keyword\">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure>\n<p><strong>参考</strong></p>\n<p><a href=\"https://blog.csdn.net/u014453898/article/details/101024805\">pytorch中VGG网络的源码解读</a></p>\n<p><a href=\"https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\">vgg.py源码</a></p>\n","categories":["机器学习","深度学习"],"tags":["机器学习, 卷积网络, VGG, Pytorch, 图像分类"]},{"title":"生命 生存 生活 生命","url":"/2020/12/20/my-life/","content":"<p>0岁时，父母给了我生命；</p>\n<p>20岁之前，努力求学，以求生存；</p>\n<p>20岁~40岁，小有成就，优雅生活；</p>\n<p>40岁之后，追求信仰，实现生命的真正意义！</p>\n","categories":["思考"],"tags":["思考"]}]